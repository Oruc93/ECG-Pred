# This script is a first draft of how to read the ECG data generated by the Matlab script

import os
from random import sample
import numpy as np
import h5py
import matplotlib.pyplot as plt
from tensorflow.keras import mixed_precision
from keras.layers import Dense, Input, BatchNormalization,  LSTM
from keras.layers import Conv1D, Conv1DTranspose, UpSampling1D, AveragePooling1D, MaxPooling1D, Reshape, Flatten
from keras.layers.merge import concatenate
from keras.models import Model
import tensorflow as tf
import tensorflow.keras as K

# Change directory to current file directory
abspath = os.path.abspath(__file__)
dname = os.path.dirname(abspath)
os.chdir(dname)

"""# function for reading out Matlab binary file.
def read_matrix(file_name):
    arr = np.fromfile(file_name, dtype='d')  # double-precision floating-point number
    arr = read_matrix("./data/ECG_5min.bin") # reads binary as numpy array
    # Reshaping array
    arr = arr.reshape((3,300000)) # Rows contain ECG. Columns time steps

with open("./data/ECG_5min.bin", newline='') as csvfile:
    spamreader = csv.reader(csvfile, delimiter=',')
    print(spamreader)
    for row in spamreader:
        print(', '.join(row))"""
        
def memorize(filename, dataset):
    """Memorizes needed data from HDF5 file
    Returns as numpy array
    
    """
    # Checks if filename is a string
    if not(isinstance(filename, str)):
        print("filename must be a string naming a H5-file.")
    # Checks if dataset is a string
    if not(isinstance(dataset, str)):
        print("dataset must be a string naming a dataset in the H5-file.")
    
    try:
        file = h5py.File(filename, "r") # pointer to h5-file
    except:
        print("H5-file not found in current directory. Choose one of the files below")
        print("Current directory:", dname)
        print([".data/" + name for name in os.listdir("./data") if "h5" in name]) # listet alle h5 Dateien im data Ordner
        print([".data/" + name for name in os.listdir("./data") if "hdf5" in name])
        print([".data/" + name for name in os.listdir() if "h5" in name]) # listet alle h5 Dateien im aktuellen Ordner
        print([".data/" + name for name in os.listdir() if "hdf5" in name])
        
    try:
        data = file[dataset] # loads pointer to dataset into variable
    except:
        print("dataset not found in H5-file. Choose one of the datasets below")
        print(file.keys())
    
    # plots the distribution of whole data
    plt.figure(1)
    plt.title("Distribution of data")
    data_flat = data[:].flatten()
    plt.hist(data_flat, bins=30)
    plt.xlabel("voltage in mV")
    plt.ylabel("occurence")
    plt.savefig("distribution of data")
    plt.close()
    
    orig_samplerate = file.attrs['samplerate'][0]
    
    return data[:], orig_samplerate # returns dataset and samplerate

def downsample(ts, orig_samplerate, samplerat):
    """downsamples time series from orig_samplerate to samplerate

    Args:
        ts (_type_): time series with orig_samplerate
        orig_samplerate (_type_): samplerate of dataset
        samplerate (_type_): samplerate we wish for
    """
    step = int(orig_samplerate/samplerat) # stepsize needed to downsample to desired samplerate
    
    # global variables
    global samplerate # setting samplerate global
    samplerate = samplerat
    
    return ts[:,::step]    

def set_items(data, INPUT_name, OUTPUT_name, length_item, orig_samplerate, scaling=1):
    """ This function pulls items from datasets
     The items are separated by Input and Output, training and test
     
     
    :param data: numpy array containing dataset
    :param INPUT_name: selection of input features
    :param OUTPUT_name: selection of output features
    :param length_item: length of items given into the neural network
    :param scaling: Scales data
    :param offset
    :return X,y,X_test,y_test: numpy arrays of training and test sets
     """    
    # Constructing toy problem sinus curve in shape of data
    """x = np.linspace(0, np.shape(data)[1]/250, num=np.shape(data)[1])
    for k in range(np.shape(data)[0]):
        ra = np.random.rand(1)*np.pi
        data[k, :] = np.sin(x + ra)"""
        
    # Normalizing time series in data
    for k in range(len(data[:,0])): # loop over all time series
        data[k,:] = (data[k,:] - np.min(data[k,:])) / (np.max(data[k,:]) - np.min(data[k,:])) # min-max scaling
        
    # Calculation of the features and slicing of time series
    print("Constructing input array ...")
    X = constr_feat(data, INPUT_name, length_item, orig_samplerate)
    print("Constructing output array ...")
    y = constr_feat(data, OUTPUT_name, length_item, orig_samplerate)
    return X, y

def constr_feat(data, NAME , length_item, orig_samplerate):
    """ This function constructs the feature from given datasets
    the interval of interest in the time series is one length_item from the end of the time series
    and length_item long
    
    :param data: numpy array containing dataset
    :param NAME: list of features. list of strings
    :param length_item: length of items given into the neural network
    :return sequence: numpy arrays of features. rows timeseries. Columns features
     """
    sequence = np.zeros((np.shape(data)[0], length_item, len(NAME))) # prebuilding empty sequence
    for k in range(len(NAME)): # loop over list of features
        name = NAME[k]
        if "lag" in name: # check if feature is of lag nature
            print("feature: lag ", int(name[4:]), "at column ", k)
            sequence[:,:,k] = data[:, -2*length_item + int(name[4:]) : -length_item + int(name[4:])]
            continue
        # calculation with convolution of padded interval and sequence of ones
        if "moving average" in name: # Calculating moving average of half second before and after. Here: 1000Hz
            # https://stackoverflow.com/questions/14313510/how-to-calculate-rolling-moving-average-using-python-numpy-scipy
            print("feature: moving average at column ", k)
            ma_win = 0.15 # window of MA in seconds
            s = int(orig_samplerate*ma_win)
            h_s = int(s/2) # half of the window length. important to for getting padding around interval of interest
            # padding with points from timeseries. This way more information in feature
            for n in range(np.shape(sequence)[0]): # loop over ecgs
                # convolution of interval of interest and sequence of ones with length samplerate
                ma = np.convolve(data[n, -2*length_item - h_s : - length_item + h_s], np.ones(s), 'valid') / s
                sequence[n, :, k] = ma[1:] # first value is discarded
            continue
    return sequence
    # return np.zeros((np.shape(data)[0], length_item, len(NAME)))

def feat_check(X,y):
    """
    Plots the different features of input and output in one diagramm
    Helps with deciding if features are reasonable and correct
    """
    print(np.shape(X))
    plt.figure(1)
    # plt.title("ECG with 5 minute duration")
    plt.plot(list(range(len(X[0,0:2000,0]))), X[0,0:2000,0])
    plt.savefig("Test-X.png")
    plt.close()
    
    print(np.shape(y))
    plt.figure(2)
    # plt.title("ECG with 5 minute duration")
    k = 0
    for n in range(len(y[0,0,:])):
        plt.plot(list(range(len(y[0,0:2000,n]))), y[0,0:2000,n] + k)
        k = k + 0.0005
    """plt.plot(list(range(len(y[0,0:2000,1]))), y[0,0:2000,1] + 0.0005)
    plt.plot(list(range(len(y[0,0:2000,2]))), y[0,0:2000,2] + 0.001)
    plt.plot(list(range(len(y[0,0:2000,3]))), y[0,0:2000,3] + 0.0015)"""
    plt.savefig("Test-y.png")
    plt.close()
    

def setup_LSTM_AE(input_shape, size, number_feat):
    """builds RNN for different sizes and number of features
    first part is an encoder architecture
    second part consists of pseudo-task branches corresponding to the selected features

    All nodes are LSTM-nodes

    :param input_shape: the shape of the input array
    :param size: the width of the first encoder layer
    :param number_feat: number of features of output (number of pseudo-tasks)
    :return model: keras model
    """
    
    # here we determine to you use mixed precision
    # Meaning that the forwardpropagation is done in float16 for higher throughput
    # And Backpropagation in float32 to keep high precision in weight adjusting
    # Warning: If custom training is used. Loss Scaling is needed. See https://www.tensorflow.org/guide/mixed_precision
    mixed_precision.set_global_policy('mixed_float16')
    
    # initialize our model
    # our input layer
    Input_encoder = Input(shape=input_shape)  # np.shape(X)[1:]
    encoder = Dense(size,
                   # return_sequences=True,
                   )(Input_encoder)  # downgrade numpy to v1.19.2 if Tensor / NumpyArray error here
    # encoder = BatchNormalization()(encoder)
    
    # our hidden layer / encoder
    # decreasing triangle
    orig_size = size  # size of layer in branches before output / decoder architecture
    while size > 2**4+1:
        size = int(size / 2)
        # encoder = LSTM(size, return_sequences=True)(encoder)
        encoder = Dense(size)(encoder)
        # encoder = BatchNormalization()(encoder)

    # pred = LSTM(size, return_sequences=True)(encoder) # toy example works without LSTM

    # branching of the pseudo-tasks
    # expanding triangle / decoder until all branches combined are as wide as the input layer
    branch_dic = {}  # dictionary for the branches
    for x in range(number_feat):
        size_branch = size
        branch_dic["branch{0}".format(x)] = LSTM(size, return_sequences=True)(encoder) # toy example works without LSTM
        branch_dic["branch{0}".format(x)] = LSTM(size, return_sequences=True)(branch_dic["branch{0}".format(x)]) # toy example works without LSTM
        branch_dic["branch{0}".format(x)] = Dense(size_branch)(branch_dic["branch{0}".format(x)])
        # size_branch = int(size_branch * 2)
        # branch_dic["branch{0}".format(x)] = LSTM(size_branch, return_sequences=True)(encoder)
        # branch_dic["branch{0}".format(x)] = BatchNormalization()(branch_dic["branch{0}".format(x)])
        while size_branch*2 <= orig_size:
            size_branch = int(size_branch * 2)
            branch_dic["branch{0}".format(x)] = Dense(size_branch)(branch_dic["branch{0}".format(x)])
            """branch_dic["branch{0}".format(x)] = LSTM(size_branch, return_sequences=True)(
                branch_dic["branch{0}".format(x)])"""
            # branch_dic["branch{0}".format(x)] = BatchNormalization()(branch_dic["branch{0}".format(x)])
        # dense outputs a regression
        branch_dic["branch{0}".format(x)] = Dense(1, activation='linear', dtype="float32")(
            branch_dic["branch{0}".format(x)])
    print("number of feat: ",number_feat)
    if number_feat>1: # check if multiple feature in output of NN
        # concatenate layer of the branch outputs
        print("Branch Werte")
        print(branch_dic.values())
        con = concatenate(branch_dic.values())
        # dense calculates, so we use it in the branches
        # this way each branch is independent from each other in the decoding part
        # and focuses on its given feature
        model = Model(Input_encoder, con)
    else: # single feature in output
        print("Branch Werte")
        print(branch_dic.values())
        print(branch_dic["branch0"])
        model = Model(Input_encoder, branch_dic["branch0"])
    
    # Add loss manually, because we use a custom loss with global variable use
    # model.add_loss(lambda: my_loss_fn(y_true, con, OUTPUT_name))
    return model

def my_init(shape, dtype=None):
    """Custom Kernel for initializing Convolution layer

    Args:
    """
    print("Goal shape", shape)
    kernel_np = np.load("2s-snippet.npy")
    print("Shape of numpy", np.shape(kernel_np))
    kernel = tf.convert_to_tensor(kernel_np, dtype=dtype)
    print("Shape of kernel 1", tf.shape(kernel))
    kernel = tf.reshape(kernel, (shape[0],1,1))
    print("Shape of kernel 2", tf.shape(kernel))
    kernel = tf.repeat(kernel, [shape[2]], axis=2)
    print("Shape of kernel 3", tf.shape(kernel))
    return kernel
    

def setup_Conv_AE_LSTM_P(input_shape, size, number_feat, samplerate):
    """builds Autoencoder for different sizes and number of features
    Encoder part are convolutional layers which downsampling to half length of timeseries with every layer
    - with kernelsize corresponding to two seconds. 2s snippets contain one heartbeat for sure
    second part consists of pseudo-task branches corresponding to the selected features
    in these branches we make a prediction with the LSTM layer
    In the decoding part we use UpSampling and Conv layer to get the back to an ecg timeseries
    
    This does not work !!!!
    We will move away from ecg prediction and concentrate on prediction of non-linear parameters

    :param input_shape: the shape of the input array
    :param size: the width of the first encoder layer
    :param number_feat: number of features of output (number of pseudo-tasks)
    :param samplerate: samplerate of measurement. Needed for kernel size in conv layer
    :return model: keras model
    """
    
        
    # here we determine to you use mixed precision
    # Meaning that the forwardpropagation is done in float16 for higher throughput
    # And Backpropagation in float32 to keep high precision in weight adjusting
    # Warning: If custom training is used. Loss Scaling is needed. See https://www.tensorflow.org/guide/mixed_precision
    mixed_precision.set_global_policy('mixed_float16')
    print("Input Shape:", input_shape)
    # initialize our model
    # our input layer
    Input_encoder = Input(shape=input_shape)  # np.shape(X)[1:]
    ds_step = 2
    orig_a_f = int(16) # first filter amount
    amount_filter = orig_a_f
    encoder = Conv1D(amount_filter, # number of columns in output. filters
                     samplerate*2, # kernel size. We look at 2s snippets
                     # strides = 1, # we convolute with overlapping kernel. This way correlation is kept for sure
                     padding = "same", # only applies kernel if it fits on input. No Padding
                     # kernel_initializer = my_init, # custom kernel initializer
                     dilation_rate=2,
                     activation = "relu"
                     )(Input_encoder)  # downgrade numpy to v1.19.2 if Tensor / NumpyArray error here
    encoder = AveragePooling1D(ds_step)(encoder)
    
    # our hidden layer / encoder
    # decreasing triangle
    orig_size = size  # size of layer in branches before output / decoder architecture
    k = int(1)
    while 2**5 > amount_filter:
        # size = int(size / 2)
        amount_filter *= 2
        encoder = Conv1D(amount_filter, # number of columns in output. filters
                     int(samplerate/k), # kernel size. We look at 2s snippets
                     # strides = 2, # we convolute with overlapping kernel. This way correlation is kept for sure
                     padding = "same", # only applies kernel if it fits on input. No Padding
                     # kernel_initializer = my_init, # custom kernel initializer
                     dilation_rate=2,
                     activation = "relu"
                     )(encoder)  # downgrade numpy to v1.19.2 if Tensor / NumpyArray error here
        encoder = AveragePooling1D(ds_step)(encoder)
        k *= 2
    
    pred = Dense(size)(encoder)
    pred = LSTM(size, return_sequences=True)(pred)
    pred = Dense(size)(pred)
    
        
    # branching of the pseudo-tasks
    # expanding triangle / decoder until all branches combined are as wide as the input layer
    branch_dic = {}  # dictionary for the branches
    latent_a_f = amount_filter
    for x in range(number_feat):
        amount_filter = latent_a_f
        branch_dic["branch{0}".format(x)] = Conv1D(amount_filter,
                                                    1,
                                                    strides=1,
                                                    padding = "same",
                                                    activation="relu")(
                                                    pred)
        branch_dic["branch{0}".format(x)] = UpSampling1D(ds_step)(branch_dic["branch{0}".format(x)])
        amount_filter /= 2
        while amount_filter >= orig_a_f:
            branch_dic["branch{0}".format(x)] = Conv1D(amount_filter,
                                                        1,
                                                        strides=1,
                                                        padding = "same",
                                                        activation="relu")(
                                                        branch_dic["branch{0}".format(x)])
            branch_dic["branch{0}".format(x)] = UpSampling1D(ds_step)(branch_dic["branch{0}".format(x)])
            amount_filter /= 2
        # outputs a regression
        branch_dic["branch{0}".format(x)] = Conv1D(1,
                                                    1,
                                                    strides=1,
                                                    padding = "same",
                                                    activation="sigmoid")(
                                                    branch_dic["branch{0}".format(x)])
    print("number of feat: ",number_feat)
    if number_feat>1: # check if multiple feature in output of NN
        # concatenate layer of the branch outputs
        print("Branch Werte")
        print(branch_dic.values())
        con = concatenate(branch_dic.values())
        # dense calculates, so we use it in the branches
        # this way each branch is independent from each other in the decoding part
        # and focuses on its given feature
        model = Model(Input_encoder, con)
    else: # single feature in output
        print("Branch Werte")
        print(branch_dic.values())
        print(branch_dic["branch0"])
        model = Model(Input_encoder, branch_dic["branch0"])
        
    # Add loss manually, because we use a custom loss with global variable use
    # model.add_loss(lambda: my_loss_fn(y_true, con, OUTPUT_name))
    return model

def setup_Conv_AE(input_shape, size, number_feat, samplerate):
    """builds Autoencoder for different sizes and number of features
    Encoder part are convolutional layers which downsampling to half length of timeseries with every layer
    - with kernelsize corresponding to two seconds. 2s snippets contain one heartbeat for sure
    second part consists of pseudo-task branches corresponding to the selected features
    in these branches we make a prediction with the LSTM layer
    In the decoding part we use UpSampling and Conv layer to get the back to an ecg timeseries

    :param input_shape: the shape of the input array
    :param size: the width of the first encoder layer
    :param number_feat: number of features of output (number of pseudo-tasks)
    :param samplerate: samplerate of measurement. Needed for kernel size in conv layer
    :return model: keras model
    """
    
        
    # here we determine to you use mixed precision
    # Meaning that the forwardpropagation is done in float16 for higher throughput
    # And Backpropagation in float32 to keep high precision in weight adjusting
    # Warning: If custom training is used. Loss Scaling is needed. See https://www.tensorflow.org/guide/mixed_precision
    mixed_precision.set_global_policy('mixed_float16')
    print("Input Shape:", input_shape)
    
    # initialize our model
    # our input layer
    Input_encoder = Input(shape=input_shape)  # np.shape(X)[1:]
    ds_step = 4
    orig_a_f = int(16) # first filter amount
    amount_filter = orig_a_f
    encoder = Conv1D(amount_filter, # number of columns in output. filters
                     samplerate*2, # kernel size. We look at 2s snippets
                     strides = 1, # we convolute with overlapping kernel. This way correlation is kept for sure. 4 Hz stride
                     padding = "same", # only applies kernel if it fits on input. No Padding
                     # kernel_initializer = my_init, # custom kernel initializer
                     dilation_rate=2,
                     activation = "relu"
                     )(Input_encoder)  # downgrade numpy to v1.19.2 if Tensor / NumpyArray error here
    encoder = AveragePooling1D(ds_step)(encoder)
    # encoder = BatchNormalization()(encoder)
    
    # our hidden layer / encoder
    # decreasing triangle
    orig_size = size  # size of layer in branches before output / decoder architecture
    k = int(1)
    while 2**5 > amount_filter:
        # size = int(size / 2)
        amount_filter *= 2
        print("Anzahlfilter Encoder:", amount_filter)
        print("Kernelgröße Encoder:", int(samplerate/k))
        encoder = Conv1D(amount_filter, # number of columns in output. filters
                     int(samplerate/k), # kernel size. We look at 2s snippets
                     # strides = 1, # we convolute with overlapping kernel. This way correlation is kept for sure
                     padding = "same", # only applies kernel if it fits on input. No Padding
                     # kernel_initializer = my_init, # custom kernel initializer
                     dilation_rate=2,
                     activation = "relu"
                     )(encoder)  # downgrade numpy to v1.19.2 if Tensor / NumpyArray error here
        encoder = AveragePooling1D(ds_step)(encoder)
        # encoder = BatchNormalization()(encoder)
        k *= 2 # due to 4Hz stride
        
    # branching of the pseudo-tasks
    # expanding triangle / decoder until all branches combined are as wide as the input layer
    branch_dic = {}  # dictionary for the branches
    latent_a_f = amount_filter
    for x in range(number_feat):
        amount_filter = latent_a_f
        # branch_dic["branch{0}".format(x)] = LSTM(size, return_sequences=True)(encoder) # toy example works without LSTM
        # branch_dic["branch{0}".format(x)] = Dense(size)(encoder) # toy example works without LSTM
        print("Anzahlfilter Decoder:", amount_filter)
        # branch_dic["branch{0}".format(x)] = UpSampling1D(4)(encoder)
        branch_dic["branch{0}".format(x)] = Conv1D(amount_filter,
                                                    1,
                                                    strides=1,
                                                    padding = "same",
                                                    activation="relu")(
                                                    encoder)
        branch_dic["branch{0}".format(x)] = UpSampling1D(ds_step)(branch_dic["branch{0}".format(x)])
        amount_filter /= 2
        while amount_filter >= orig_a_f:
            print("Anzahlfilter Decoder:", amount_filter)
            branch_dic["branch{0}".format(x)] = Conv1D(amount_filter,
                                                        1,
                                                        strides=1,
                                                        padding = "same",
                                                        activation="relu")(
                                                        branch_dic["branch{0}".format(x)])
            branch_dic["branch{0}".format(x)] = UpSampling1D(ds_step)(branch_dic["branch{0}".format(x)])
            amount_filter /= 2
        # branch_dic["branch{0}".format(x)] = BatchNormalization()(branch_dic["branch{0}".format(x)])
        # outputs a regression
        # branch_dic["branch{0}".format(x)] = UpSampling1D(64)(branch_dic["branch{0}".format(x)])
        branch_dic["branch{0}".format(x)] = Conv1D(1,
                                                            1,
                                                            strides=1,
                                                            padding = "same",
                                                            activation="sigmoid")(
                                                            branch_dic["branch{0}".format(x)])
        # branch_dic["branch{0}".format(x)] = Dense(1,
        #                                           activation="linear")(branch_dic["branch{0}".format(x)])
    print("number of feat: ",number_feat)
    if number_feat>1: # check if multiple feature in output of NN
        # concatenate layer of the branch outputs
        print("Branch Werte")
        print(branch_dic.values())
        con = concatenate(branch_dic.values())
        # dense calculates, so we use it in the branches
        # this way each branch is independent from each other in the decoding part
        # and focuses on its given feature
        model = Model(Input_encoder, con)
    else: # single feature in output
        print("Branch Werte")
        print(branch_dic.values())
        print(branch_dic["branch0"])
        model = Model(Input_encoder, branch_dic["branch0"])
        
    # Add loss manually, because we use a custom loss with global variable use
    # model.add_loss(lambda: my_loss_fn(y_true, con, OUTPUT_name))"""
    return model

def setup_Conv_AE_Dense(input_shape, size, number_feat, samplerate):
    """builds Autoencoder for different sizes and number of features
    Encoder part are convolutional layers which downsampling to half length of timeseries with every layer
    - with kernelsize corresponding to two seconds. 2s snippets contain one heartbeat for sure
    second part consists of pseudo-task branches corresponding to the selected features
    in these branches we make a prediction with the LSTM layer
    In the decoding part we use UpSampling and Conv layer to get the back to an ecg timeseries

    :param input_shape: the shape of the input array
    :param size: the width of the first encoder layer
    :param number_feat: number of features of output (number of pseudo-tasks)
    :param samplerate: samplerate of measurement. Needed for kernel size in conv layer
    :return model: keras model
    """
    
        
    # here we determine to you use mixed precision
    # Meaning that the forwardpropagation is done in float16 for higher throughput
    # And Backpropagation in float32 to keep high precision in weight adjusting
    # Warning: If custom training is used. Loss Scaling is needed. See https://www.tensorflow.org/guide/mixed_precision
    mixed_precision.set_global_policy('mixed_float16')
    print("Input Shape:", input_shape)
    
    # initialize our model
    # our input layer
    Input_encoder = Input(shape=input_shape)  # np.shape(X)[1:]
    ds_step = 2
    orig_a_f = int(16) # first filter amount
    amount_filter = orig_a_f
    encoder = Conv1D(amount_filter, # number of columns in output. filters
                     samplerate*2, # kernel size. We look at 2s snippets
                     strides = 1, # we convolute with overlapping kernel. This way correlation is kept for sure. 4 Hz stride
                     padding = "same", # only applies kernel if it fits on input. No Padding
                     # kernel_initializer = my_init, # custom kernel initializer
                     dilation_rate=2,
                     activation = "relu"
                     )(Input_encoder)  # downgrade numpy to v1.19.2 if Tensor / NumpyArray error here
    encoder = AveragePooling1D(ds_step)(encoder)
    
    # our hidden layer / encoder
    # decreasing triangle
    orig_size = size  # size of layer in branches before output / decoder architecture
    k = int(1)
    while 2**5 > amount_filter:
        # size = int(size / 2)
        amount_filter *= 2
        print("Anzahlfilter Encoder:", amount_filter)
        print("Kernelgröße Encoder:", int(samplerate/k))
        encoder = Conv1D(amount_filter, # number of columns in output. filters
                     int(samplerate/k), # kernel size. We look at 2s snippets
                     # strides = 1, # we convolute with overlapping kernel. This way correlation is kept for sure
                     padding = "same", # only applies kernel if it fits on input. No Padding
                     # kernel_initializer = my_init, # custom kernel initializer
                     dilation_rate=2,
                     activation = "relu"
                     )(encoder)  # downgrade numpy to v1.19.2 if Tensor / NumpyArray error here
        encoder = AveragePooling1D(ds_step)(encoder)
        # encoder = BatchNormalization()(encoder)
        k *= 2 # due to 4Hz stride
    encoder = Dense(size)(encoder)
    
    # branching of the pseudo-tasks
    # expanding triangle / decoder until all branches combined are as wide as the input layer
    branch_dic = {}  # dictionary for the branches
    latent_a_f = amount_filter
    for x in range(number_feat):
        amount_filter = latent_a_f
        # branch_dic["branch{0}".format(x)] = LSTM(size, return_sequences=True)(encoder) # toy example works without LSTM
        # branch_dic["branch{0}".format(x)] = Dense(size)(encoder) # toy example works without LSTM
        print("Anzahlfilter Decoder:", amount_filter)
        # branch_dic["branch{0}".format(x)] = UpSampling1D(4)(encoder)
        branch_dic["branch{0}".format(x)] = Conv1D(amount_filter,
                                                    1,
                                                    strides=1,
                                                    padding = "same",
                                                    activation="relu")(
                                                    encoder)
        branch_dic["branch{0}".format(x)] = UpSampling1D(ds_step)(branch_dic["branch{0}".format(x)])
        amount_filter /= 2
        while amount_filter >= orig_a_f:
            print("Anzahlfilter Decoder:", amount_filter)
            branch_dic["branch{0}".format(x)] = Conv1D(amount_filter,
                                                        1,
                                                        strides=1,
                                                        padding = "same",
                                                        activation="relu")(
                                                        branch_dic["branch{0}".format(x)])
            branch_dic["branch{0}".format(x)] = UpSampling1D(ds_step)(branch_dic["branch{0}".format(x)])
            amount_filter /= 2
        # branch_dic["branch{0}".format(x)] = BatchNormalization()(branch_dic["branch{0}".format(x)])
        # outputs a regression
        # branch_dic["branch{0}".format(x)] = UpSampling1D(64)(branch_dic["branch{0}".format(x)])
        branch_dic["branch{0}".format(x)] = Conv1D(1,
                                                            1,
                                                            strides=1,
                                                            padding = "same",
                                                            activation="sigmoid")(
                                                            branch_dic["branch{0}".format(x)])
        # branch_dic["branch{0}".format(x)] = Dense(1,
        #                                           activation="linear")(branch_dic["branch{0}".format(x)])
    print("number of feat: ",number_feat)
    if number_feat>1: # check if multiple feature in output of NN
        # concatenate layer of the branch outputs
        print("Branch Werte")
        print(branch_dic.values())
        con = concatenate(branch_dic.values())
        # dense calculates, so we use it in the branches
        # this way each branch is independent from each other in the decoding part
        # and focuses on its given feature
        model = Model(Input_encoder, con)
    else: # single feature in output
        print("Branch Werte")
        print(branch_dic.values())
        print(branch_dic["branch0"])
        model = Model(Input_encoder, branch_dic["branch0"])
        
    # Add loss manually, because we use a custom loss with global variable use
    # model.add_loss(lambda: my_loss_fn(y_true, con, OUTPUT_name))"""
    return model

def setup_Conv_DS_Dense_E_LSTM_P(input_shape, size, number_feat, samplerate):
    """Pre-Training like Mehari and Strodthoff

    :param input_shape: the shape of the input array
    :param size: the width of the first encoder layer
    :param number_feat: number of features of output (number of pseudo-tasks)
    :param samplerate: samplerate of measurement. Needed for kernel size in conv layer
    :return model: keras model
    """
    
        
    # here we determine to you use mixed precision
    # Meaning that the forwardpropagation is done in float16 for higher throughput
    # And Backpropagation in float32 to keep high precision in weight adjusting
    # Warning: If custom training is used. Loss Scaling is needed. See https://www.tensorflow.org/guide/mixed_precision
    mixed_precision.set_global_policy('mixed_float16')
    print("Input Shape:", input_shape)
    # initialize our model
    # our input layer
    Input_encoder = Input(shape=input_shape)  # np.shape(X)[1:]
    N = 256
    encoder = Dense(N)(Input_encoder)
    encoder = Dense(N)(encoder)
    encoder = Dense(N)(encoder)
    encoder = Dense(N)(encoder)
    
    pred = LSTM(N, return_sequences=True)(encoder)
    pred = LSTM(N, return_sequences=True)(pred)
    
    output = Dense(N)(pred)
    model = Model(Input_encoder, output)
    
    return model, Model(Input_encoder, pred)


def draw_model(model):
    """
    plots model and saves in model.ong
    """
    tf.keras.utils.plot_model(model)
    
def setup_LSTM_nn(input_shape, size, number_feat):
    """builds RNN for different sizes and number of features
    one hidden LSTM layer

    All nodes are LSTM-nodes

    :param input_shape: the shape of the input array
    :param size: the width of the first encoder layer
    :param number_feat: number of features of output (number of pseudo-tasks)
    :return model: keras model
    """
    
    # here we determine to you use mixed precision
    # Meaning that the forwardpropagation is done in float16 for higher throughput
    # And Backpropagation in float32 to keep high precision in weight adjusting
    # Warning: If custom training is used. Loss Scaling is needed. See https://www.tensorflow.org/guide/mixed_precision
    mixed_precision.set_global_policy('mixed_float16')
    
    # initialize our model
    # our input layer
    Input_encoder = Input(shape=input_shape)  # np.shape(X)[1:]
    hidden = LSTM(size,
                   return_sequences=True,
                   )(Input_encoder)  # downgrade numpy to v1.19.2 if Tensor / NumpyArray error here
    # hidden = BatchNormalization()(hidden)
    hidden = LSTM(size,
                   return_sequences=True,
                   )(hidden)  # downgrade numpy to v1.19.2 if Tensor / NumpyArray error here
    # hidden = BatchNormalization()(hidden)
    
    output = Dense(number_feat, activation='linear', dtype="float32")(hidden)
    model = Model(Input_encoder, output)
       
    # Add loss manually, because we use a custom loss with global variable use
    # model.add_loss(lambda: my_loss_fn(y_true, con, OUTPUT_name))
    return model

def my_loss_fn(y_true, y_pred):
        """
        Custom LOSS function

        Goal:  weighted sum of LOSSes of each Feature
                - Weights are for different columns of Output Tensor
                    - Weights decrease for each feature
                    - this way the gradient for each additional feature is more gentle compared to previous features
                    - this gives a loose order in which the LOSSes are minimized
        """
        squarred_differences = []
        # print("v value", v.eval())
        # Here we calculate the squared difference of each timestep of each sample in each column and weight it
        for k in range(len(y_true[0,0,:])): # loop over columns in output array
            mse = K.losses.MeanSquaredError() # function for LOSS of choice
            # Calculate LOSS for each column and weight the result
            # append über tensorflow und unterschied in zeit messen
            squarred_differences.append(tf.cast(mse(y_true[:,:,k], y_pred[:,:,k]),tf.float32) * 10 ** k) # best results with multiplication of 10 to power of k with features from easy to difficult
            # tf.print(v, output_stream=sys.stderr)
            # uarred_differences.write(k, mse(y_true[:,:,k], y_pred[:,:,k]))
            # tf.print("Loss individual")
            # tf.print(uarred_differences.read(k))
            # tf.print(squarred_differences)
        sd = tf.stack(squarred_differences) # Concat the LOSSes of each feature
        # tf.print("Loss stacked")
        # tf.print(uarred_differences.stack())
        # tf.print(sd)
        # print("sd dimension", K.backend.int_shape(sd))
        # Here we calculate the mean of each column
        loss = tf.reduce_mean(sd, axis=-1)  # Note the `axis=-1`
        # tf.print("Loss sum mean")
        # tf.print(loss)
        # tf.print(tf.reduce_mean(uarred_differences.stack(), axis=-1))
        # loss = tf.reduce_mean(squarred_differences.stack(), axis=-1)
        # print("Loss dimension", K.backend.int_shape(loss))
        return loss
    
def check_data(X,y,X_test,y_test):
    # Check of Dataset
    plt.figure(1)
    plt.title("Examples from datasets 1000Hz")
    plt.plot(list(range(len(X[0,:]))), X[0,:])
    plt.plot(list(range(len(y[0,:,0]))), y[0,:,0])
    # plt.plot(list(range(len(X_test[0,:,0]))), X_test[0,:,0])
    # plt.plot(list(range(len(y_test[0,:,0]))), y_test[0,:,0])
    plt.legend(["X", "y", "X_test", "y_test"])
    plt.savefig("Full-Plot Xy datasets")
    plt.close()
    
    """plt.figure(1)
    print("length of 250Hz vector", len(y[0,::4,0]))
    plt.title("Examples from datasets 250Hz")
    plt.plot(list(range(len(X[0,::4]))), X[0,::4])
    plt.plot(list(range(len(y[0,::4,0]))), y[0,::4,0])
    # plt.plot(list(range(len(X_test[0,:,0]))), X_test[0,:,0])
    # plt.plot(list(range(len(y_test[0,:,0]))), y_test[0,:,0])
    plt.legend(["X", "y", "X_test", "y_test"])
    plt.savefig("Full-Plot Xy datasets - 250Hz")
    plt.close()"""
    
    # print("Mittelwert")
    MEAN = np.mean(X,axis=0)
    VAR = np.var(X,axis=0)
    plt.figure(1)
    plt.title("Examples from datasets")
    # plt.plot(list(range(len(MEAN))), MEAN)
    plt.plot(list(range(len(VAR))), VAR)
    # plt.plot(list(range(len(y[0,:,0]))), y[0,:,0])
    # plt.plot(list(range(len(X_test[0,:,0]))), X_test[0,:,0])
    # plt.plot(list(range(len(y_test[0,:,0]))), y_test[0,:,0])
    plt.legend(["MEAN", "VAR", "X_test", "y_test"])
    plt.savefig("Mittelwert")
    plt.close()
    # print(np.shape(MEAN))
    
    """normalizer = tf.keras.layers.Normalization()
    normalizer.adapt(X)
    X_norm = normalizer(X)
    plt.figure(1)
    plt.title("normalized data")
    plt.plot(list(range(len(X_norm[0,:]))), X_norm[0,:])
    plt.plot(list(range(len(y[0,:,0]))), y[0,:,0])
    # plt.plot(list(range(len(X_test[0,:,0]))), X_test[0,:,0])
    # plt.plot(list(range(len(y_test[0,:,0]))), y_test[0,:,0])
    plt.legend(["X", "y", "X_test", "y_test"])
    plt.savefig("Full-Plot Xy datasets")
    plt.close()"""